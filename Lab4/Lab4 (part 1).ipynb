{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pvu5_5MNusNL",
    "outputId": "0666e4b0-982b-446d-c201-521ba3876d49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3E4g2XbaoQe8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K4LJzXSxpDh"
   },
   "source": [
    "#TensorFlow\n",
    "TensorFlow is like a toolbox made by Google to help you build and train machine learning and deep learning models.\n",
    "You can use it to build models for things like:\n",
    "*   Image recognition\n",
    "*   Language translation\n",
    "*   Predicting stock prices\n",
    "---\n",
    "#Keras\n",
    "Keras is like a friendly interface (a helper) that sits on top of TensorFlow.\n",
    "* It lets you build AI models more easily using fewer lines of code.\n",
    "* Instead of doing all the complicated stuff manually, Keras gives you simple blocks (like layers, models, optimizers) to stack and play with.\n",
    "* It’s like using LEGO blocks to build a house instead of carving each brick by hand.\n",
    "---\n",
    "#`tensorflow.keras.layers`\n",
    "In `tensorflow.keras`, the `layers` module gives you building blocks to create neural networks.\n",
    "* Each layer takes input, does some math, and passes output to the next layer.\n",
    "* The layers module has pre-made layer types like:\n",
    "    * `Dense` – fully connected layer (every neuron is connected to every neuron in the next layer)\n",
    "    * `Conv2D` – for images (convolutional layer)\n",
    "    * `Dropout` – randomly turns off some neurons to prevent overfitting\n",
    "    * `Flatten`, `ReLU`, `LSTM`, etc.\n",
    "\n",
    "Instead of writing math manually, you can say:\n",
    "```\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# A layer with 64 neurons and ReLU activation\n",
    "my_layer = layers.Dense(64, activation='relu')\n",
    "```\n",
    "This one line gives you a full, trainable layer in a neural network.\n",
    "\n",
    "Without Keras all training bits have to be manually written including writing the activation function and updating the weight and gradients. But TensorFlow does give you the advantage to use highly optimized data, hardware acceleration, methods to calculate and update gradients/weights etc. Therefore TensorFlow is useful in building ML models for specific training purposes but if you want to use already established models like CNN or RNN, its better and easier to use Keras.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPQU5OMj2bLM"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pewTvoDKBFwh"
   },
   "source": [
    "This line creates a placeholder for input data that will be fed into your model.\n",
    "\n",
    "`tf.keras.Input(...)`\n",
    "* This creates a Keras input layer — the entry point of your neural network.\n",
    "* It tells the model: \"This is what kind of data I expect.\"\n",
    "\n",
    "`shape=(784,)`\n",
    "* This means each input sample has 784 features.\n",
    "* Common in flattened images — for example:\n",
    "  * A 28x28 grayscale image = 784 pixels → flattened to a vector\n",
    "  * Like in the MNIST digit datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_57I5wc4CTjH"
   },
   "outputs": [],
   "source": [
    "dense = layers.Dense(64 ,activation =\"relu\")\n",
    "x = dense (inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGt0Yg1CDj7i"
   },
   "source": [
    "Here `dense` is a neural network that takes input and converts to 64 outputs. `x` will store the outputs from he neural network after processing the `inputs`. It takes 784 data points and gives 64 outputs. Therefore `x` stores 64 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLoespUUGvv3"
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation =\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krCCwASxHUpo"
   },
   "source": [
    "We then add the next layer, which further extracts features. This will process `x` from the previous step and\n",
    "result in a new `x` that is also 64-dimensional, before passing those outputs to a final layer that is 10-dimensional. The outputs of that layer go into a variable called `outputs`.\n",
    "\n",
    "Each of those outputs represents one of the digits. Having defined the layers of the network we can now construct\n",
    "the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "ORC61tN4HfKJ",
    "outputId": "fac6cda6-825b-497c-e3c0-828b3b765309"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaRq8a7UKMHc"
   },
   "source": [
    "`model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")`\n",
    "\n",
    "This line creates a Keras model object — the actual neural network you can train, evaluate, and use to make predictions.\n",
    "\n",
    "`inputs=inputs`\n",
    "\n",
    "This is the input layer you defined earlier. It tells the model: \"Here’s where the data enters the network.\"\n",
    "\n",
    "`outputs=outputs`\n",
    "\n",
    "This is the final layer of your model — the output layer.\n",
    "It tells the model: \"Here’s what the model should return.\"\n",
    "\n",
    "`name=\"mnist_model\"`\n",
    "\n",
    "This gives your model a name (optional), useful for saving/loading or viewing in TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOQx_ntHLjGy"
   },
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KR3seHslLmex"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape (10000,784 ).astype (\"float32\")/ 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y92IiODePLzg"
   },
   "source": [
    "`.reshape(60000, 784)` This flattens each 28×28 image into a 1D vector of 784 values. This is needed because many basic neural networks (like Dense layers) expect flat input vectors, not 2D images.\n",
    "\n",
    "`/ 255` Normalizes the pixel values to be between 0 and 1 instead of 0 to 255. This makes training faster and more stable.\n",
    "\n",
    "\\\n",
    "\\\n",
    "Having loaded the data, compile it as follows. You will need to specify a loss function (to determine how good\n",
    "the predictions are), an optimiser, and accuracy metrics to report on how well the predictions do. You can then\n",
    "train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRjW20PQP0KQ",
    "outputId": "13a1c92a-28c0-453e-fdfa-e4345124ae5e"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  optimizer = tf.keras.optimizers.RMSprop(),\n",
    "  metrics =[\"accuracy\"],)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
    "\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test accuracy :\", test_scores [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HCjZQZeSSsf"
   },
   "source": [
    "`batch_size=64`\n",
    "\n",
    "The model doesn’t train on all 60,000 samples at once. Instead, it processes them in mini-batches of 64 samples at a time. This makes training faster and more memory-efficient.\n",
    "\n",
    "`epochs=2`\n",
    "\n",
    "An epoch = one full pass through all the training data.\n",
    "Here, the model will go through the full training set 2 times.\n",
    "\n",
    "`validation_split=0.2`\n",
    "\n",
    "20% of x_train and y_train is set aside for validation. The model uses that 20% to test itself after each epoch (but doesn’t learn from it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4RaqTNfUs3N"
   },
   "source": [
    "#Confusion Matrix of the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "2CMPRbslU00j",
    "outputId": "f37ce51f-8757-416e-fe94-90e1bb199592"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test).argmax(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix(y_test, predictions))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D34uEjIWAHc"
   },
   "source": [
    "The result of the predict method is 10 outputs for each input image. These represent the likelihood that the image represents each image, so there is the likelihood that the image is a 0, the likelihood that its a 1, and\n",
    "so on. What you need to do is find the largest of these, which will give you the most likely prediction - the\n",
    "argmax method will do this for you. The axis=1 argument will return the highest value in each row so that\n",
    "you can do the whole lot in one go."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
