{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Pvu5_5MNusNL",
        "outputId": "0666e4b0-982b-446d-c201-521ba3876d49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m581.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3E4g2XbaoQe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TensorFlow\n",
        "TensorFlow is like a toolbox made by Google to help you build and train machine learning and deep learning models.\n",
        "You can use it to build models for things like:\n",
        "*   Image recognition\n",
        "*   Language translation\n",
        "*   Predicting stock prices\n",
        "---\n",
        "#Keras\n",
        "Keras is like a friendly interface (a helper) that sits on top of TensorFlow.\n",
        "* It lets you build AI models more easily using fewer lines of code.\n",
        "* Instead of doing all the complicated stuff manually, Keras gives you simple blocks (like layers, models, optimizers) to stack and play with.\n",
        "* It’s like using LEGO blocks to build a house instead of carving each brick by hand.\n",
        "---\n",
        "#`tensorflow.keras.layers`\n",
        "In `tensorflow.keras`, the `layers` module gives you building blocks to create neural networks.\n",
        "* Each layer takes input, does some math, and passes output to the next layer.\n",
        "* The layers module has pre-made layer types like:\n",
        "    * `Dense` – fully connected layer (every neuron is connected to every neuron in the next layer)\n",
        "    * `Conv2D` – for images (convolutional layer)\n",
        "    * `Dropout` – randomly turns off some neurons to prevent overfitting\n",
        "    * `Flatten`, `ReLU`, `LSTM`, etc.\n",
        "\n",
        "Instead of writing math manually, you can say:\n",
        "```\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# A layer with 64 neurons and ReLU activation\n",
        "my_layer = layers.Dense(64, activation='relu')\n",
        "```\n",
        "This one line gives you a full, trainable layer in a neural network.\n",
        "\n",
        "Without Keras all training bits have to be manually written including writing the activation function and updating the weight and gradients. But TensorFlow does give you the advantage to use highly optimized data, hardware acceleration, methods to calculate and update gradients/weights etc. Therefore TensorFlow is useful in building ML models for specific training purposes but if you want to use already established models like CNN or RNN, its better and easier to use Keras.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7K4LJzXSxpDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(784,))"
      ],
      "metadata": {
        "id": "FPQU5OMj2bLM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line creates a placeholder for input data that will be fed into your model.\n",
        "\n",
        "`tf.keras.Input(...)`\n",
        "* This creates a Keras input layer — the entry point of your neural network.\n",
        "* It tells the model: \"This is what kind of data I expect.\"\n",
        "\n",
        "`shape=(784,)`\n",
        "* This means each input sample has 784 features.\n",
        "* Common in flattened images — for example:\n",
        "  * A 28x28 grayscale image = 784 pixels → flattened to a vector\n",
        "  * Like in the MNIST digit datase"
      ],
      "metadata": {
        "id": "pewTvoDKBFwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense = layers.Dense(64 ,activation =\"relu\")\n",
        "x = dense (inputs)"
      ],
      "metadata": {
        "id": "_57I5wc4CTjH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here `dense` is a neural network that takes input and converts to 64 outputs. `x` will store the outputs from he neural network after processing the `inputs`. It takes 784 data points and gives 64 outputs. Therefore `x` stores 64 values."
      ],
      "metadata": {
        "id": "qGt0Yg1CDj7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Dense(64, activation =\"relu\")(x)\n",
        "outputs = layers.Dense(10)(x)"
      ],
      "metadata": {
        "id": "kLoespUUGvv3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then add the next layer, which further extracts features. This will process `x` from the previous step and\n",
        "result in a new `x` that is also 64-dimensional, before passing those outputs to a final layer that is 10-dimensional. The outputs of that layer go into a variable called `outputs`.\n",
        "\n",
        "Each of those outputs represents one of the digits. Having defined the layers of the network we can now construct\n",
        "the model:"
      ],
      "metadata": {
        "id": "krCCwASxHUpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "ORC61tN4HfKJ",
        "outputId": "fac6cda6-825b-497c-e3c0-828b3b765309"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mnist_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mnist_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m50,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")`\n",
        "\n",
        "This line creates a Keras model object — the actual neural network you can train, evaluate, and use to make predictions.\n",
        "\n",
        "`inputs=inputs`\n",
        "\n",
        "This is the input layer you defined earlier. It tells the model: \"Here’s where the data enters the network.\"\n",
        "\n",
        "`outputs=outputs`\n",
        "\n",
        "This is the final layer of your model — the output layer.\n",
        "It tells the model: \"Here’s what the model should return.\"\n",
        "\n",
        "`name=\"mnist_model\"`\n",
        "\n",
        "This gives your model a name (optional), useful for saving/loading or viewing in TensorBoard."
      ],
      "metadata": {
        "id": "YaRq8a7UKMHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data:"
      ],
      "metadata": {
        "id": "lOQx_ntHLjGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784).astype(\"float32\")/255\n",
        "x_test = x_test.reshape (10000,784 ).astype (\"float32\")/ 255"
      ],
      "metadata": {
        "id": "KR3seHslLmex"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.reshape(60000, 784)` This flattens each 28×28 image into a 1D vector of 784 values. This is needed because many basic neural networks (like Dense layers) expect flat input vectors, not 2D images.\n",
        "\n",
        "`/ 255` Normalizes the pixel values to be between 0 and 1 instead of 0 to 255. This makes training faster and more stable.\n",
        "\n",
        "\\\n",
        "\\\n",
        "Having loaded the data, compile it as follows. You will need to specify a loss function (to determine how good\n",
        "the predictions are), an optimiser, and accuracy metrics to report on how well the predictions do. You can then\n",
        "train the model."
      ],
      "metadata": {
        "id": "y92IiODePLzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "  optimizer = tf.keras.optimizers.RMSprop(),\n",
        "  metrics =[\"accuracy\"],)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
        "\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test accuracy :\", test_scores [1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRjW20PQP0KQ",
        "outputId": "13a1c92a-28c0-453e-fdfa-e4345124ae5e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1262 - val_accuracy: 0.9607 - val_loss: 0.1315\n",
            "Epoch 2/2\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0944 - val_accuracy: 0.9659 - val_loss: 0.1172\n",
            "313/313 - 0s - 1ms/step - accuracy: 0.9646 - loss: 0.1167\n",
            "Test accuracy : 0.9646000266075134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`batch_size=64`\n",
        "\n",
        "The model doesn’t train on all 60,000 samples at once. Instead, it processes them in mini-batches of 64 samples at a time. This makes training faster and more memory-efficient.\n",
        "\n",
        "`epochs=2`\n",
        "\n",
        "An epoch = one full pass through all the training data.\n",
        "Here, the model will go through the full training set 2 times.\n",
        "\n",
        "`validation_split=0.2`\n",
        "\n",
        "20% of x_train and y_train is set aside for validation. The model uses that 20% to test itself after each epoch (but doesn’t learn from it)."
      ],
      "metadata": {
        "id": "1HCjZQZeSSsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix of the trained model:"
      ],
      "metadata": {
        "id": "B4RaqTNfUs3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test).argmax(axis=1)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix(y_test, predictions))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "2CMPRbslU00j",
        "outputId": "f37ce51f-8757-416e-fe94-90e1bb199592"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the predict method is 10 outputs for each input image. These represent the likelihood that the image represents each image, so there is the likelihood that the image is a 0, the likelihood that its a 1, and\n",
        "so on. What you need to do is find the largest of these, which will give you the most likely prediction - the\n",
        "argmax method will do this for you. The axis=1 argument will return the highest value in each row so that\n",
        "you can do the whole lot in one go."
      ],
      "metadata": {
        "id": "6D34uEjIWAHc"
      }
    }
  ]
}